{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HeitorAl/machine-learning-practitioner-dio/blob/main/Transfer_Learning_DIO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "6M0BkXLXWsse"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from keras.applications import MobileNet\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lk2wKYwG2os"
      },
      "source": [
        "### Atenção\n",
        "\n",
        "A caixa abaixo foi executada apenas para criar os arquivos de teste e treino no drive, não é necessário executá-la novamente"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Juwu9b7LxIFY",
        "outputId": "d2e869a1-44de-414e-8273-2da49498a4db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conjuntos de treino e teste criados com sucesso!\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "# Caminhos de entrada e saída\n",
        "base_dir = \"drive/My Drive/Colab Notebooks/PetImages\"  # Caminho da pasta com as subpastas 'cats' e 'dogs'\n",
        "output_dir = \"drive/My Drive/Colab Notebooks/PetImages\"  # Caminho para salvar os conjuntos de treino e teste\n",
        "\n",
        "# Listar imagens e rótulos\n",
        "image_paths = []\n",
        "labels = []\n",
        "\n",
        "for label in os.listdir(base_dir):  # Classes, como 'cats' e 'dogs'\n",
        "    class_dir = os.path.join(base_dir, label)\n",
        "    for img in os.listdir(class_dir):\n",
        "        image_paths.append(os.path.join(class_dir, img))\n",
        "        labels.append(label)\n",
        "\n",
        "# Divisão usando train_test_split\n",
        "train_paths, test_paths, train_labels, test_labels = train_test_split(\n",
        "    image_paths, labels, train_size=0.7, stratify=labels, random_state=42\n",
        ")\n",
        "\n",
        "# Copiar arquivos para os diretórios de treino e teste\n",
        "for path, label in zip(train_paths, train_labels):\n",
        "    train_dir = os.path.join(output_dir, \"train\", label)\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    shutil.copy(path, os.path.join(train_dir, os.path.basename(path)))\n",
        "\n",
        "for path, label in zip(test_paths, test_labels):\n",
        "    test_dir = os.path.join(output_dir, \"test\", label)\n",
        "    os.makedirs(test_dir, exist_ok=True)\n",
        "    shutil.copy(path, os.path.join(test_dir, os.path.basename(path)))\n",
        "\n",
        "print(\"Conjuntos de treino e teste criados com sucesso!\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDVd0Yu3Wx4O",
        "outputId": "494a787b-f64e-4faf-e351-98cbdd418d91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-95e9054bab38>:1: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  model = MobileNet(weights=\"imagenet\", include_top=False)\n"
          ]
        }
      ],
      "source": [
        "model = MobileNet(weights=\"imagenet\", include_top=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "v-bbDtzBb_JH"
      },
      "outputs": [],
      "source": [
        "x = model.output\n",
        "x = GlobalAveragePooling2D()(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-iq4owArcFOL"
      },
      "outputs": [],
      "source": [
        "x = Dense(50, activation='relu')(x)\n",
        "preds = Dense(1, activation='sigmoid')(x)\n",
        "model = Model(inputs=model.input, outputs=preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEFTmThHcWxW",
        "outputId": "90c063be-2df9-42a7-ac71-f3200c94d537"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 input_layer\n",
            "1 conv1\n",
            "2 conv1_bn\n",
            "3 conv1_relu\n",
            "4 conv_dw_1\n",
            "5 conv_dw_1_bn\n",
            "6 conv_dw_1_relu\n",
            "7 conv_pw_1\n",
            "8 conv_pw_1_bn\n",
            "9 conv_pw_1_relu\n",
            "10 conv_pad_2\n",
            "11 conv_dw_2\n",
            "12 conv_dw_2_bn\n",
            "13 conv_dw_2_relu\n",
            "14 conv_pw_2\n",
            "15 conv_pw_2_bn\n",
            "16 conv_pw_2_relu\n",
            "17 conv_dw_3\n",
            "18 conv_dw_3_bn\n",
            "19 conv_dw_3_relu\n",
            "20 conv_pw_3\n",
            "21 conv_pw_3_bn\n",
            "22 conv_pw_3_relu\n",
            "23 conv_pad_4\n",
            "24 conv_dw_4\n",
            "25 conv_dw_4_bn\n",
            "26 conv_dw_4_relu\n",
            "27 conv_pw_4\n",
            "28 conv_pw_4_bn\n",
            "29 conv_pw_4_relu\n",
            "30 conv_dw_5\n",
            "31 conv_dw_5_bn\n",
            "32 conv_dw_5_relu\n",
            "33 conv_pw_5\n",
            "34 conv_pw_5_bn\n",
            "35 conv_pw_5_relu\n",
            "36 conv_pad_6\n",
            "37 conv_dw_6\n",
            "38 conv_dw_6_bn\n",
            "39 conv_dw_6_relu\n",
            "40 conv_pw_6\n",
            "41 conv_pw_6_bn\n",
            "42 conv_pw_6_relu\n",
            "43 conv_dw_7\n",
            "44 conv_dw_7_bn\n",
            "45 conv_dw_7_relu\n",
            "46 conv_pw_7\n",
            "47 conv_pw_7_bn\n",
            "48 conv_pw_7_relu\n",
            "49 conv_dw_8\n",
            "50 conv_dw_8_bn\n",
            "51 conv_dw_8_relu\n",
            "52 conv_pw_8\n",
            "53 conv_pw_8_bn\n",
            "54 conv_pw_8_relu\n",
            "55 conv_dw_9\n",
            "56 conv_dw_9_bn\n",
            "57 conv_dw_9_relu\n",
            "58 conv_pw_9\n",
            "59 conv_pw_9_bn\n",
            "60 conv_pw_9_relu\n",
            "61 conv_dw_10\n",
            "62 conv_dw_10_bn\n",
            "63 conv_dw_10_relu\n",
            "64 conv_pw_10\n",
            "65 conv_pw_10_bn\n",
            "66 conv_pw_10_relu\n",
            "67 conv_dw_11\n",
            "68 conv_dw_11_bn\n",
            "69 conv_dw_11_relu\n",
            "70 conv_pw_11\n",
            "71 conv_pw_11_bn\n",
            "72 conv_pw_11_relu\n",
            "73 conv_pad_12\n",
            "74 conv_dw_12\n",
            "75 conv_dw_12_bn\n",
            "76 conv_dw_12_relu\n",
            "77 conv_pw_12\n",
            "78 conv_pw_12_bn\n",
            "79 conv_pw_12_relu\n",
            "80 conv_dw_13\n",
            "81 conv_dw_13_bn\n",
            "82 conv_dw_13_relu\n",
            "83 conv_pw_13\n",
            "84 conv_pw_13_bn\n",
            "85 conv_pw_13_relu\n",
            "86 global_average_pooling2d\n",
            "87 dense\n",
            "88 dense_1\n"
          ]
        }
      ],
      "source": [
        "for i, layer in enumerate(model.layers):\n",
        "  print(i, layer.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GWKUuvVbgaAa"
      },
      "outputs": [],
      "source": [
        "for layer in model.layers[:88]:\n",
        "  layer.trainable=False\n",
        "for layer in model.layers[88:]:\n",
        "  layer.trainable=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hQcwAd0TciCX"
      },
      "outputs": [],
      "source": [
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0cnsVsDGR8S",
        "outputId": "a4cd6b19-7cfb-43d3-d920-db0821a56388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/TiffImagePlugin.py:949: UserWarning: Truncated File Read\n",
            "  warnings.warn(str(msg))\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def verify_images(data_dir):\n",
        "  \"\"\"\n",
        "  Verifies the integrity of images in a given directory.\n",
        "\n",
        "  Args:\n",
        "    data_dir: The path to the directory containing image data.\n",
        "\n",
        "  Raises:\n",
        "    ValueError: If an image cannot be opened by PIL.\n",
        "  \"\"\"\n",
        "  for root, _, files in os.walk(data_dir):\n",
        "    for file in files:\n",
        "      if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "        try:\n",
        "          filepath = os.path.join(root, file)\n",
        "          img = Image.open(filepath)  # Attempt to open with PIL\n",
        "          img.verify()  # Verify image integrity\n",
        "          img.close()\n",
        "        except (IOError, SyntaxError) as e:\n",
        "          print(f\"Error with image: {filepath} - {e}\")\n",
        "          # Consider removing or replacing the problematic image\n",
        "          os.remove(filepath)  # Uncomment to remove corrupted image\n",
        "\n",
        "# Verify images in your training and test directories\n",
        "verify_images('drive/MyDrive/Colab Notebooks/PetImages/train')\n",
        "verify_images('drive/MyDrive/Colab Notebooks/PetImages/test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "MIPQZskrdR9s",
        "outputId": "8df96d17-1cae-4831-95f9-c306b7c5bae3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\\n                                   shear_range = 0.4,\\n                                   zoom_range = 0.4,\\n                                   height_shift_range = 0.3,\\n                                   width_shift_range = 0.3,\\n                                   rotation_range = 50,\\n                                   horizontal_flip = True)\\n\\ntest_datagen = ImageDataGenerator(rescale = 1./255)\\n\\ntraining_set = train_datagen.flow_from_directory('drive/MyDrive/Colab Notebooks/PetImages/train',\\n                                                 target_size = (224,224),\\n                                                 batch_size = batch_size,\\n                                                 class_mode = 'binary')\\n\\ntest_set = test_datagen.flow_from_directory('drive/MyDrive/Colab Notebooks/PetImages/test',\\n                                            target_size = (224,224),\\n                                            batch_size = batch_size,\\n                                            class_mode = 'binary')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "\n",
        "# Função personalizada para ignorar erros ao carregar batches\n",
        "def safe_flow_from_directory(datagen, directory, target_size, batch_size, class_mode):\n",
        "    generator = datagen.flow_from_directory(\n",
        "        directory=directory,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=class_mode\n",
        "    )\n",
        "    while True:  # Loop para manter o gerador ativo\n",
        "        try:\n",
        "            batch = next(generator)\n",
        "            yield batch\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao carregar lote: {e}\")\n",
        "            continue\n",
        "\n",
        "# Configurar o ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# Criar os geradores seguros para treinamento e teste\n",
        "training_set = safe_flow_from_directory(\n",
        "    datagen=train_datagen,\n",
        "    directory='drive/MyDrive/Colab Notebooks/PetImages/train',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "test_set = safe_flow_from_directory(\n",
        "    datagen=test_datagen,\n",
        "    directory='drive/MyDrive/Colab Notebooks/PetImages/test',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\"\"\"\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.4,\n",
        "                                   zoom_range = 0.4,\n",
        "                                   height_shift_range = 0.3,\n",
        "                                   width_shift_range = 0.3,\n",
        "                                   rotation_range = 50,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('drive/MyDrive/Colab Notebooks/PetImages/train',\n",
        "                                                 target_size = (224,224),\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 class_mode = 'binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory('drive/MyDrive/Colab Notebooks/PetImages/test',\n",
        "                                            target_size = (224,224),\n",
        "                                            batch_size = batch_size,\n",
        "                                            class_mode = 'binary')\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BuAhQlR0ERdV"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=Adam(learning_rate = 0.0001),loss='binary_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UYf4OcXEZVE",
        "outputId": "48bfe6bd-78f0-4316-ee9e-10587f42b195"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 17441 images belonging to 2 classes.\n",
            "Epoch 1/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889ms/step - accuracy: 0.4854 - loss: 1.1819Found 7474 images belonging to 2 classes.\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 1s/step - accuracy: 0.4854 - loss: 1.1817 - val_accuracy: 0.4798 - val_loss: 1.0795\n",
            "Epoch 2/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 358ms/step - accuracy: 0.4616 - loss: 1.0625 - val_accuracy: 0.4748 - val_loss: 0.9775\n",
            "Epoch 3/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 326ms/step - accuracy: 0.4865 - loss: 0.9988 - val_accuracy: 0.4778 - val_loss: 0.9861\n",
            "Epoch 4/10\n",
            "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 331ms/step - accuracy: 0.4902 - loss: 0.9544 - val_accuracy: 0.4873 - val_loss: 0.9237\n",
            "Epoch 5/10\n",
            "\u001b[1m189/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m15s\u001b[0m 253ms/step - accuracy: 0.5042 - loss: 0.9083"
          ]
        }
      ],
      "source": [
        "history = model.fit(x=training_set,\n",
        "                   steps_per_epoch = int(8000/batch_size),\n",
        "                   epochs=10,\n",
        "                   validation_data = test_set,\n",
        "                   validation_steps = int(2000/batch_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8UnAaj2cu2p"
      },
      "outputs": [],
      "source": [
        "model.save('transfer_learning_mobilenet.keras')\n",
        "from google.colab import files\n",
        "files.download('transfer_learning_mobilenet.keras')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skimage import io\n",
        "\n",
        "url = \"https://super.abril.com.br/wp-content/uploads/2024/11/1811-cachorro-layout_site.jpg?quality=70&strip=info&w=1024&h=682&crop=1\"\n",
        "image = io.imread(url)\n",
        "\n",
        "plt.imshow(image)\n",
        "plt.title(\"Imagem obtida\")\n",
        "plt.tight_layout()\n"
      ],
      "metadata": {
        "id": "-33pMP1i_zEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "test_image = image\n",
        "teste_image = cv2.resize(image, (224,224))\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "test_image = test_image/255\n",
        "\n",
        "if model.predict(test_image)[0][0] > 0.5:\n",
        "  print(\"Previsão: cachorro\")\n",
        "else:\n",
        "  print(\"Previsão: gato\")"
      ],
      "metadata": {
        "id": "6_M8xQNkKyv0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Lo2B9RXmSgDR_ltfB9ZZfbDftkvXqHK3",
      "authorship_tag": "ABX9TyPSCpW4wu5QiEXNMrGdO/NA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}